Homework 2
================
Malika Top
2024-09-25

## Problem 1

``` r
nyc_transit = 
  read_csv("data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") |> 
  janitor::clean_names()

nyc_subset =
  nyc_transit |> 
  select(line:entry, vending, ada) |> 
  mutate(
    entry = case_match(entry, "YES" ~ TRUE, "NO" ~ FALSE)
  )
# OR:
# nyc_subset =
#   nyc_transit |> 
#   select(line:entry, vending, ada) |> 
#   mutate(
#     entry = ifelse(entry == "YES", TRUE, FALSE )
#   )
```

This dataframe contains information about the NYC Transit system’s
entrances and for all stations and lines. Each row represents a station
and has information about which line it belongs to, the daytime routes
that serve that station, whether it has stairs at the entrance, if it is
ADA compliant, and presumably if it has an OMNY vending machine there.
If there is a repeat of a station, that means there are multiple
entrances. For example, looking at the first few rows:

``` r
slice(nyc_subset, 1:3)
```

    ## # A tibble: 3 × 19
    ##   line     station_name station_latitude station_longitude route1 route2 route3
    ##   <chr>    <chr>                   <dbl>             <dbl> <chr>  <chr>  <chr> 
    ## 1 4 Avenue 25th St                  40.7             -74.0 R      <NA>   <NA>  
    ## 2 4 Avenue 25th St                  40.7             -74.0 R      <NA>   <NA>  
    ## 3 4 Avenue 36th St                  40.7             -74.0 N      R      <NA>  
    ## # ℹ 12 more variables: route4 <chr>, route5 <chr>, route6 <chr>, route7 <chr>,
    ## #   route8 <dbl>, route9 <dbl>, route10 <dbl>, route11 <dbl>,
    ## #   entrance_type <chr>, entry <lgl>, vending <chr>, ada <lgl>

Stations are identified by station_name and line, so the first row is
25th St 4 Av. We see R in the `route1` column, which means that the R
train serves this station during the day. Looking at the third row
though, we see N in `route1` and R in `route2` which means both the N
and R train serve this station (but run different routes.)

After reading the data in and accounting for NAs, I cleaned using the
`janitor` package’s `clean_names()` function, and select 19 out of the
original 32 columns of interest. I then converted the `entry` variable
to be of `logical` type, rather than just character. The dimensions of
the dataset are 19 columns and 1868 rows. However, this data is not tidy
because the `route1`… `route11` values are spread across separate
columns, when it could be just one variable, say `route`.

``` r
nyc_dist_subset = 
  nyc_subset |> 
  mutate(
    station_id = paste(station_name, line) # stations are identified both by name and by line 
  ) |> 
  relocate(station_id, .after = station_name) |> 
  distinct(station_id, .keep_all = TRUE)

# lapply(nyc_dist_subset, class) # we see that routes 8, 9, 10, 11 are `numeric` class
tidy_stations =
  nyc_dist_subset |> 
  mutate(
    route8 = as.character(route8),
    route9 = as.character(route9),
    route10 = as.character(route10),
    route11 = as.character(route11)
  ) |> 
  pivot_longer(
    route1:route11,
    names_to = "route_number",
    values_to = "route_name"
  ) |> 
  relocate(route_number, route_name, .after = station_id) |> 
  drop_na(route_name)

head(tidy_stations)
```

    ## # A tibble: 6 × 11
    ##   line     station_name station_id      route_number route_name station_latitude
    ##   <chr>    <chr>        <chr>           <chr>        <chr>                 <dbl>
    ## 1 4 Avenue 25th St      25th St 4 Aven… route1       R                      40.7
    ## 2 4 Avenue 36th St      36th St 4 Aven… route1       N                      40.7
    ## 3 4 Avenue 36th St      36th St 4 Aven… route2       R                      40.7
    ## 4 4 Avenue 45th St      45th St 4 Aven… route1       R                      40.6
    ## 5 4 Avenue 53rd St      53rd St 4 Aven… route1       R                      40.6
    ## 6 4 Avenue 59th St      59th St 4 Aven… route1       N                      40.6
    ## # ℹ 5 more variables: station_longitude <dbl>, entrance_type <chr>,
    ## #   entry <lgl>, vending <chr>, ada <lgl>

### What proportion of station entrances / exits without vending allow entrance?

``` r
# Does entry == FALSE mean that it's an exit?
no_vending_entry = 
  nyc_subset |> 
  filter(vending == "NO") |> # 183 obs
  filter(entry == TRUE) # 69 obs
```

The proportion of station entrances/exits without vending that allow
entrance are $\frac{69}{183}$ = 0.377

### How many stations are ADA compliant?

``` r
ada_compliant = 
  tidy_stations |> 
  filter(ada==TRUE)
```

There are 293 stations compliant with ADA.

### How many distinct stations serve the A train? Of the stations that serve the A train, how many are ADA compliant?

``` r
service_A = filter(tidy_stations, route_name == "A")
ada_A = filter(service_A, ada == TRUE)
```

There are 60 distinct stations that serve the A. Of the stations serving
the A, there are 17 stations that are ADA compliant.

## Problem 2

``` r
mr_trash = read_excel("data/202309 Trash Wheel Collection Data.xlsx", 
                      range = "A2:N587", 
                      sheet=1) |> 
            janitor::clean_names() |> 
            filter(row_number() <= n()-1) |>  #gets rid of the last row which is totals
            mutate(
              sports_balls = as.integer(round(sports_balls)),
              year = as.integer(year),
              trash_wheel = "mr"
            ) |> 
            relocate(trash_wheel)
prof_trash = read_excel("data/202309 Trash Wheel Collection Data.xlsx", 
                      range = "A2:M109",
                      sheet=2) |> 
              janitor::clean_names()|> 
              filter(row_number() <= n()-1) |> #gets rid of the last row which is totals
              mutate(
                trash_wheel = "professor"
                )|> 
            relocate(trash_wheel)

gwynda = read_excel("data/202309 Trash Wheel Collection Data.xlsx", 
                    range = "A2:L159",
                    sheet=4) |> 
              janitor::clean_names()|> 
              filter(row_number() <= n()-2) |>  #gets rid of the last row which is totals
                                                #also the second to last which was just empty
              mutate(
                trash_wheel = "gwynda"
              )|> 
            relocate(trash_wheel)

combined_trash = 
  bind_rows(mr_trash, prof_trash, gwynda) 
```

``` r
total_trash_wt = sum(pull(prof_trash, weight_tons))
cigs_06_22 = 
  sum(
    combined_trash |> 
    filter(trash_wheel == "gwynda" &
           month == "June" 
         & year == 2022) |> 
    select(cigarette_butts)
  )
```

## Problem 3

``` r
bakers_df = read_csv("data/gbb_datasets/bakers.csv") |> 
  janitor::clean_names() |> 
  separate_wider_delim(baker_name, " ", names=c("first_name",
                                                "last_name")) 
```

    ## Rows: 120 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker Name, Baker Occupation, Hometown
    ## dbl (2): Series, Baker Age
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
bakers_df$first_name[bakers_df$first_name=="Jo"] <- "Joanne"  

bakes_df = read_csv("data/gbb_datasets/bakes.csv")|> 
  janitor::clean_names() |> 
  rename(first_name = baker) |> 
  mutate(first_name = gsub('"', '', first_name))
```

    ## Rows: 548 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker, Signature Bake, Show Stopper
    ## dbl (2): Series, Episode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
bakes_df$first_name[bakes_df$first_name=="Jo"] <- "Joanne"
           
results_df = read_csv("data/gbb_datasets/results.csv", skip=2) |> 
  janitor::clean_names() |> 
  rename(first_name = baker)
```

    ## Rows: 1136 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (2): baker, result
    ## dbl (3): series, episode, technical
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

The `bakers_df` has information about the contestants, for which there
are 12 each series, and a total of 10 series. The number of episodes per
series ranges from 6-10. `bakes_df` contains information about how
someone did in a technical, the Signature they made, and the
Showstopper. Upon initial data exploration, we see that `results_df`
includes contestants up to Series 10, but `bakes_df` only has
information up to Series 8, which means we might want to apply any
mutative join starting with `results_df` so we don’t lose any additional
information. There are many missing NA values but that makes sense,
because once a contestant is eliminated, there should not be information
on their bakes/how they did.

For cleaning, I separated the original `baker_name` column in
`bakers_df` to have just first name, to match the other tables.

In thinking about how to combine these dataframes together, I considered
using `left_join` because I didn’t want to miss any data from
`results_df`, whereas using `right_join` or `full_join` would not be
necessary since we know that the `bakes_df` does not have all the
information to match `results_df` anyways.

``` r
comb_df = results_df |> 
  left_join(bakes_df, by = c("series", "episode", "first_name")) |> 
  left_join(bakers_df, by = c("series", "first_name"))
```

### Checking for completeness and correctness

``` r
anti_join(results_df, comb_df, by = c("series", "episode", "first_name"))
```

    ## # A tibble: 0 × 5
    ## # ℹ 5 variables: series <dbl>, episode <dbl>, first_name <chr>,
    ## #   technical <dbl>, result <chr>

``` r
anti_join(bakes_df, comb_df, by = c("series", "episode", "first_name"))
```

    ## # A tibble: 0 × 5
    ## # ℹ 5 variables: series <dbl>, episode <dbl>, first_name <chr>,
    ## #   signature_bake <chr>, show_stopper <chr>

``` r
anti_join(bakers_df, comb_df, by = c("series", "first_name"))
```

    ## # A tibble: 0 × 6
    ## # ℹ 6 variables: first_name <chr>, last_name <chr>, series <dbl>,
    ## #   baker_age <dbl>, baker_occupation <chr>, hometown <chr>

Checking the merged dataframe against `results_df`, we get an empty
table, so that one checks out. However, antijoining with `bakes_df`
returned an 8x5 tibble showing that “Jo” of Series 2 was left out. After
some sifting, I found out the reason why is because the same contestant
is named “Jo” in the This combined dataframe has information about how
each contestant did, what they baked, and basic background facts like
hometown.

``` r
comb_df = 
  comb_df |> 
  relocate(signature_bake, .before = "technical") |> 
  relocate(result, .after = "show_stopper")
```
